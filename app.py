"""
AgroConsulting - Hugging Face Spaces Deployment
Assistant IA Agricole pour le Burkina Faso

Point d'entr√©e principal pour Hugging Face Spaces
"""

import os
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any, Tuple

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Ajouter le r√©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))
sys.path.insert(0, str(Path(__file__).parent))

# Configuration pour Hugging Face Spaces
HF_SPACE = os.getenv("SPACE_ID") is not None
HF_TOKEN = os.getenv("HF_TOKEN") or os.getenv("HUGGINGFACE_API_TOKEN")

# Chemins des donn√©es
DATA_DIR = Path("./data")
CORPUS_PATH = DATA_DIR / "corpus.json"
EMBEDDINGS_PATH = DATA_DIR / "embeddings.npy"
FAISS_INDEX_DIR = DATA_DIR / "faiss_db"

# Cr√©er les r√©pertoires si n√©cessaire
DATA_DIR.mkdir(exist_ok=True)
FAISS_INDEX_DIR.mkdir(exist_ok=True)

# ============================================================================
# IMPORT DES MODULES
# ============================================================================

try:
    from src.embeddings import EmbeddingPipeline
    from src.vector_store import FAISSVectorStore
    from src.llm_handler import LLMHandler, LLMBackend, GenerationConfig
    from src.data_loader import ensure_data_available, load_data_from_hf
    logger.info("‚úÖ Modules RAG import√©s avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import modules: {e}")
    raise

# Configuration donn√©es HF Hub
HF_DATA_REPO_ID = os.getenv("HF_DATA_REPO_ID") or os.getenv("HF_REPO_ID")

# ============================================================================
# INITIALISATION DU SYST√àME RAG
# ============================================================================

class AgroConsultingRAG:
    """Classe principale pour le syst√®me RAG AgroConsulting"""
    
    def __init__(self):
        self.embedding_model = None
        self.vector_store = None
        self.llm_handler = None
        self.initialized = False
        logger.info("üöÄ Initialisation AgroConsulting RAG...")
    
    def initialize(self):
        """Initialise tous les composants du syst√®me RAG"""
        try:
            logger.info("=" * 70)
            logger.info("üîß INITIALISATION DU SYST√àME RAG")
            logger.info("=" * 70)
            
            # 0. V√©rifier/charger les donn√©es
            if HF_DATA_REPO_ID:
                logger.info(f"üì• V√©rification donn√©es depuis HF Hub: {HF_DATA_REPO_ID}")
                ensure_data_available(DATA_DIR, HF_DATA_REPO_ID)
            else:
                logger.info("üìÇ Utilisation donn√©es locales")
                if not CORPUS_PATH.exists():
                    logger.warning("‚ö†Ô∏è Corpus local non trouv√©. Utilisez HF_DATA_REPO_ID pour charger depuis HF Hub")
            
            # 1. Mod√®le d'embeddings
            logger.info("üìä Chargement du mod√®le d'embeddings...")
            self.embedding_model = EmbeddingPipeline(str(CORPUS_PATH))
            self.embedding_model.initialize_embedding_model()
            logger.info(f"‚úÖ Embeddings charg√©s: {self.embedding_model.model_name}")
            
            # 2. Vector store (FAISS)
            logger.info("üóÇÔ∏è Chargement du vector store (FAISS)...")
            self.vector_store = FAISSVectorStore(str(FAISS_INDEX_DIR))
            
            # V√©rifier si l'index existe
            index_exists = (
                (FAISS_INDEX_DIR / "faiss_index.index").exists() and
                (FAISS_INDEX_DIR / "corpus_data.pkl").exists()
            )
            
            if index_exists:
                logger.info("üìÇ Index FAISS existant d√©tect√©, chargement...")
                success = self.vector_store.load()
                if success:
                    stats = self.vector_store.get_statistics()
                    logger.info(f"‚úÖ Vector store charg√©: {stats.get('total_documents', 0)} documents")
                else:
                    logger.warning("‚ö†Ô∏è √âchec chargement index, cr√©ation n√©cessaire")
                    self._create_index()
            else:
                logger.info("üìù Index FAISS non trouv√©, cr√©ation...")
                self._create_index()
            
            # 3. LLM Handler (utiliser HuggingFace API sur HF Spaces)
            logger.info("ü§ñ Initialisation du LLM Handler...")
            
            # Utiliser un mod√®le plus l√©ger pour HF Spaces (meilleure disponibilit√©)
            hf_model = os.getenv("HF_LLM_MODEL", "mistralai/Mistral-7B-Instruct-v0.1")
            
            self.llm_handler = LLMHandler(
                backend=LLMBackend.HUGGINGFACE,  # Utiliser HF API sur Spaces
                huggingface_model=hf_model,
                generation_config=GenerationConfig(
                    temperature=0.1,
                    max_tokens=250,  # R√©duit pour √©conomiser les tokens
                    repeat_penalty=1.2,
                ),
                enable_cache=False,  # D√©sactiver cache sur Spaces (ressources limit√©es)
                hf_api_token=HF_TOKEN,
            )
            
            # V√©rifier sant√© du LLM
            health = self.llm_handler.health_check()
            logger.info(f"‚úÖ LLM Backend: {health['active_backend']}")
            
            self.initialized = True
            logger.info("=" * 70)
            logger.info("‚úÖ SYST√àME RAG INITIALIS√â AVEC SUCC√àS")
            logger.info("=" * 70)
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation: {e}")
            import traceback
            traceback.print_exc()
            self.initialized = False
            return False
    
    def _create_index(self):
        """Cr√©e l'index FAISS depuis le corpus et les embeddings"""
        try:
            import json
            import numpy as np
            
            # Charger corpus
            if not CORPUS_PATH.exists():
                logger.error(f"‚ùå Corpus introuvable: {CORPUS_PATH}")
                raise FileNotFoundError(f"Corpus non trouv√©: {CORPUS_PATH}")
            
            logger.info(f"üìñ Chargement corpus: {CORPUS_PATH}")
            with open(CORPUS_PATH, 'r', encoding='utf-8') as f:
                corpus = json.load(f)
            logger.info(f"‚úÖ Corpus charg√©: {len(corpus)} documents")
            
            # Charger ou g√©n√©rer embeddings
            if EMBEDDINGS_PATH.exists():
                logger.info(f"üìä Chargement embeddings: {EMBEDDINGS_PATH}")
                embeddings = np.load(EMBEDDINGS_PATH)
                logger.info(f"‚úÖ Embeddings charg√©s: shape {embeddings.shape}")
            else:
                logger.info("üîß G√©n√©ration des embeddings...")
                if not self.embedding_model:
                    self.embedding_model = EmbeddingPipeline(str(CORPUS_PATH))
                    self.embedding_model.initialize_embedding_model()
                
                # G√©n√©rer embeddings avec batch size r√©duit pour √©conomiser la m√©moire
                texts = [doc.get('text', doc.get('contenu', '')) for doc in corpus]
                batch_size = int(os.getenv("EMBEDDING_BATCH_SIZE", "16"))  # R√©duit par d√©faut
                embeddings = self.embedding_model.embedding_model.encode(
                    texts,
                    batch_size=batch_size,
                    show_progress_bar=True,
                    convert_to_numpy=True,
                    normalize_embeddings=True  # Normaliser pour meilleure performance
                )
                
                # Sauvegarder embeddings
                np.save(EMBEDDINGS_PATH, embeddings)
                logger.info(f"‚úÖ Embeddings g√©n√©r√©s et sauvegard√©s: {embeddings.shape}")
            
            # Normaliser corpus pour FAISS
            normalized_corpus = []
            for i, doc in enumerate(corpus):
                normalized_doc = {
                    'id': doc.get('id', doc.get('chunk_id', f'doc_{i}')),
                    'titre': doc.get('titre', doc.get('title', 'Document')),
                    'contenu': doc.get('text', doc.get('contenu', doc.get('content', ''))),
                    'source': doc.get('source', doc.get('source_institution', 'Unknown')),
                    'organisme': doc.get('organisme', doc.get('source_institution', 'Unknown')),
                    'type': doc.get('type', 'general')
                }
                normalized_corpus.append(normalized_doc)
            
            # Cr√©er index FAISS
            logger.info("üèóÔ∏è Cr√©ation index FAISS...")
            self.vector_store.create_index(normalized_corpus, embeddings)
            logger.info("‚úÖ Index FAISS cr√©√© avec succ√®s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation index: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def answer_question(self, question: str, max_results: int = 3) -> Dict[str, Any]:
        """R√©pond √† une question agricole"""
        if not self.initialized:
            return {
                "success": False,
                "reponse": "Syst√®me non initialis√©. Veuillez patienter...",
                "sources": [],
                "error": "System not initialized"
            }
        
        try:
            logger.info(f"‚ùì Question: {question}")
            
            # 1. G√©n√©rer embedding de la question
            question_embedding = self.embedding_model.embedding_model.encode([question])[0]
            
            # 2. Recherche vectorielle
            search_results = self.vector_store.search(question_embedding, k=max_results)
            
            if not search_results:
                return {
                    "success": False,
                    "reponse": "Je n'ai pas trouv√© de documents pertinents dans ma base de connaissances pour r√©pondre √† cette question.",
                    "sources": []
                }
            
            # 3. Pr√©parer contexte pour LLM
            context_docs = []
            sources_info = []
            
            for result in search_results:
                context_docs.append({
                    "text": result.document_text,
                    "metadata": result.metadata
                })
                sources_info.append({
                    "titre": result.metadata.get("titre", "Document"),
                    "source": result.metadata.get("source", "Unknown"),
                    "organisme": result.metadata.get("organisme", "Unknown"),
                    "pertinence": float(result.similarity_score)
                })
            
            # 4. G√©n√©rer r√©ponse avec LLM
            llm_response = self.llm_handler.generate_answer(
                question,
                context_docs,
                template=None  # Utiliser template par d√©faut
            )
            
            # 5. Construire r√©ponse finale
            return {
                "success": llm_response.success,
                "reponse": llm_response.text,
                "sources": sources_info,
                "metadata": {
                    "backend": llm_response.backend,
                    "model": llm_response.model,
                    "generation_time": llm_response.generation_time,
                    "documents_used": len(search_results)
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement question: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "reponse": f"Erreur lors du traitement: {str(e)}",
                "sources": [],
                "error": str(e)
            }

# ============================================================================
# INITIALISATION GLOBALE
# ============================================================================

rag_system = AgroConsultingRAG()

# Initialiser au d√©marrage
def init_system():
    """Initialise le syst√®me RAG"""
    return rag_system.initialize()

# ============================================================================
# INTERFACE GRADIO
# ============================================================================

import gradio as gr

def process_question(question: str, history: List[List[str]]) -> Tuple[List[List[str]], str]:
    """Traite une question et retourne la r√©ponse"""
    if not question.strip():
        return history, ""
    
    # Ajouter question √† l'historique
    history.append([question, None])
    
    # Obtenir r√©ponse
    response = rag_system.answer_question(question, max_results=3)
    
    # Formater r√©ponse
    if response["success"]:
        reponse_text = response["reponse"]
        
        # Ajouter sources si disponibles
        if response.get("sources"):
            reponse_text += "\n\nüìö **Sources:**\n"
            for i, source in enumerate(response["sources"][:3], 1):
                reponse_text += f"{i}. {source['titre']} ({source['organisme']}) - Pertinence: {source['pertinence']:.2f}\n"
    else:
        reponse_text = f"‚ùå Erreur: {response.get('reponse', 'Erreur inconnue')}"
    
    # Mettre √† jour historique
    history[-1][1] = reponse_text
    
    return history, ""

# CSS personnalis√©
CSS = """
.gradio-container {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}
.main-header {
    text-align: center;
    padding: 20px;
    background: linear-gradient(135deg, #2d5016 0%, #558b2f 100%);
    color: white;
    border-radius: 10px;
    margin-bottom: 20px;
}
"""

# Cr√©er l'interface Gradio
def create_interface():
    """Cr√©e l'interface Gradio"""
    
    # En-t√™te
    header = gr.HTML("""
    <div class="main-header">
        <h1>üåæ AgroConsulting - Assistant IA Agricole</h1>
        <p>Posez vos questions sur l'agriculture au Burkina Faso</p>
    </div>
    """)
    
    # Chatbot
    chatbot = gr.Chatbot(
        label="üí¨ Chat",
        height=500,
        show_label=True,
        container=True,
        bubble_full_width=False
    )
    
    # Champ de saisie
    question_input = gr.Textbox(
        label="Votre question",
        placeholder="Ex: Quel engrais utiliser pour le mil en saison s√®che ?",
        lines=2,
        max_lines=5
    )
    
    # Boutons
    with gr.Row():
        submit_btn = gr.Button("Envoyer üì§", variant="primary", scale=2)
        clear_btn = gr.Button("Effacer üóëÔ∏è", variant="secondary", scale=1)
    
    # √âtat pour l'historique
    state = gr.State([])
    
    # √âv√©nements
    def submit(question, history):
        new_history, _ = process_question(question, history or [])
        return new_history, "", new_history
    
    def clear():
        return [], None, []
    
    submit_btn.click(
        fn=submit,
        inputs=[question_input, state],
        outputs=[chatbot, question_input, state]
    )
    
    question_input.submit(
        fn=submit,
        inputs=[question_input, state],
        outputs=[chatbot, question_input, state]
    )
    
    clear_btn.click(
        fn=clear,
        outputs=[chatbot, question_input, state]
    )
    
    # Interface
    interface = gr.Blocks(css=CSS, theme=gr.themes.Soft())
    
    with interface:
        header
        chatbot
        question_input
        with gr.Row():
            submit_btn
            clear_btn
        state
        gr.Markdown("""
        ### üìù Exemples de questions:
        - Quel engrais utiliser pour le mil ?
        - Comment prot√©ger le ma√Øs des ravageurs ?
        - Quand planter le sorgho au Burkina Faso ?
        - Techniques de conservation des sols
        - Maladies courantes du riz
        """)
    
    return interface

# ============================================================================
# POINT D'ENTR√âE PRINCIPAL
# ============================================================================

def main():
    """Fonction principale pour Hugging Face Spaces"""
    logger.info("üöÄ D√©marrage AgroConsulting sur Hugging Face Spaces")
    
    # Initialiser le syst√®me
    logger.info("‚è≥ Initialisation du syst√®me RAG (cela peut prendre quelques minutes)...")
    init_success = init_system()
    
    if not init_success:
        logger.error("‚ùå √âchec initialisation, d√©marrage en mode d√©grad√©")
        # Cr√©er interface minimale en cas d'√©chec
        interface = gr.Interface(
            fn=lambda x: "‚ùå Syst√®me non disponible. Veuillez r√©essayer plus tard.",
            inputs="text",
            outputs="text",
            title="üåæ AgroConsulting - Syst√®me non disponible",
            description="Le syst√®me est en cours d'initialisation. Veuillez patienter..."
        )
    else:
        # Cr√©er interface compl√®te
        interface = create_interface()
    
    # Lancer l'interface
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )

if __name__ == "__main__":
    main()

