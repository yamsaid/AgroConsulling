import json
import re
from tqdm import tqdm
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def advanced_clean_text(text):
    """
    Version avancÃ©e du nettoyage pour le post-traitement
    """
    if not text:
        return ""
    
    # Nettoyage en plusieurs passes
    cleaning_steps = [
        # 1. Nettoyage des artefacts d'extraction
        (r'---\s*Page\s*\d+\s*---', ''),
        (r'---+\s*--+', ''),
        (r'_{3,}', ''),
        (r'\*{3,}', ''),
        
        # 2. Nettoyage des sÃ©parateurs de ligne
        (r'\n+', ' '),
        (r'\r+', ' '),
        (r'\t+', ' '),
        
        # 3. Correction des cÃ©sures
        (r'(\w+)-\s+(\w+)', r'\1\2'),
        
        # 4. Nettoyage des caractÃ¨res indÃ©sirables
        (r'[^\w\s.,;:!?()\-â€“â€”Â«Â»Â°%â‚¬$@/\\+*=&]', ''),
        
        # 5. Nettoyage des numÃ©ros de page
        (r'\bPage\s+\d+\b', ''),
        (r'\b\d+\s*/\s*\d+\b', ''),
        (r'\bvol\.?\s*\d+\b', '', re.IGNORECASE),
        (r'\bno\.?\s*\d+\b', '', re.IGNORECASE),
        
        # 6. Normalisation des espaces
        (r'\s+', ' '),
        
        # 7. Correction ponctuation
        (r'\s+([.,;:!?)])', r'\1'),
        (r'([(])\s+', r'\1'),
        (r'\s+â€“\s+', ' â€“ '),  # Garde les tirets cadratins espacÃ©s
        (r'\s+-\s+', ' - '),  # Garde les traits d'union espacÃ©s
    ]
    
    cleaned_text = text
    for step in cleaning_steps:
        if len(step) == 3:
            # Tuple avec flags: (pattern, replacement, flags)
            pattern, replacement, flags = step
            cleaned_text = re.sub(pattern, replacement, cleaned_text, flags=flags)
        elif len(step) == 2:
            # Tuple sans flags: (pattern, replacement)
            pattern, replacement = step
            cleaned_text = re.sub(pattern, replacement, cleaned_text)
        else:
            logger.warning(f"Ã‰tape de nettoyage invalide ignorÃ©e: {step}")
    
    return cleaned_text.strip()

def clean_existing_corpus(input_path, output_path):
    """
    Nettoie un corpus existant sans reprocesser les PDFs
    """
    logger.info(f"Chargement du corpus depuis {input_path}")
    
    with open(input_path, 'r', encoding='utf-8') as f:
        corpus = json.load(f)
    
    logger.info(f"Corpus chargÃ©: {len(corpus)} chunks")
    
    # Nettoyage de chaque chunk
    cleaned_corpus = []
    removed_chunks = 0
    
    for chunk in tqdm(corpus, desc="Nettoyage des chunks"):
        original_text = chunk['text']
        cleaned_text = advanced_clean_text(original_text)
        
        # Ne garder que les chunks qui ont encore du contenu significatif
        if len(cleaned_text) >= 15:  # Au moins 15 caractÃ¨res
            chunk['text'] = cleaned_text
            #chunk['original_length'] = len(original_text)
            chunk['length'] = len(cleaned_text)
            cleaned_corpus.append(chunk)
        else:
            removed_chunks += 1
    
    # Sauvegarde du corpus nettoyÃ©
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(cleaned_corpus, f, ensure_ascii=False, indent=2)
    
    # Statistiques
    logger.info(f"\nðŸ“Š RÃ‰SULTATS DU NETTOYAGE:")
    logger.info(f"Chunks initiaux: {len(corpus)}")
    logger.info(f"Chunks aprÃ¨s nettoyage: {len(cleaned_corpus)}")
    logger.info(f"Chunks supprimÃ©s (trop courts): {removed_chunks}")
    logger.info(f"Taux de conservation: {(len(cleaned_corpus)/len(corpus))*100:.1f}%")
    
    # AperÃ§u des amÃ©liorations
    if len(cleaned_corpus) > 0:
        logger.info("\nðŸ” APERÃ‡U AVANT/APRÃˆS:")
        for i in range(min(3, len(corpus))):
            original = corpus[i]['text'][:100] + "..." if len(corpus[i]['text']) > 100 else corpus[i]['text']
            cleaned = cleaned_corpus[i]['text'][:100] + "..." if len(cleaned_corpus[i]['text']) > 100 else cleaned_corpus[i]['text']
            logger.info(f"Chunk {i+1}:")
            logger.info(f"  AVANT: {original}")
            logger.info(f"  APRÃˆS: {cleaned}")
            logger.info(f"  " + "-"*50)

def main():
    input_corpus = "./data/corpus.json"
    output_corpus = "./data/corpus_cleaned.json"
    
    clean_existing_corpus(input_corpus, output_corpus)
    logger.info(f"âœ“ Corpus nettoyÃ© sauvegardÃ© dans: {output_corpus}")

if __name__ == "__main__":
    main()